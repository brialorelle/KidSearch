exp$categoryNum = as.numeric(exp$categoryNum)
## Step 3: Preprocess data
# count how many trials per subject
trialCount=exp %>%
group_by(sub) %>%
summarise(trials=sum(phase=='SixItems'), correctTrials=sum(correct==1 & phase=='SixItems'), errors=sum(correct==0 & phase=='SixItems'), slow=sum(RT>4000 & phase=='SixItems' & correct==1))
# what percentage of all trials were incorrect?
round(mean(trialCount$errors/trialCount$trials)*100,2)
# what percentage of correct trials were slow?
round(mean(trialCount$slow/trialCount$correctTrials)*100,2)
# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
exp.tidy=exp %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in experiment 3 only.
# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
exp.tidy=exp.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
# Store included subs
includedSubs=unique(exp.tidy$sub)
# How many trials are included in each condition in this subset of children?
trialCountIncludedSubs=exp.tidy %>%
group_by(sub) %>%
filter(is.element(sub,includedSubs)) %>%
summarise(trialCount=length(RT), uniformCount=sum(conditionNum==1), mixedCount=sum(conditionNum==2))
# overall how many trials (and sd)
round(mean(trialCountIncludedSubs$trialCount),2)
round(sd(trialCountIncludedSubs$trialCount),2)
# how many trials on average per condition?
round(mean(trialCountIncludedSubs$uniformCount),2)
round(mean(trialCountIncludedSubs$mixedCount),2)
# Compute accuracy means
exp.accuracy=exp %>%
group_by(sub,conditionName, category) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) %>% # for technical error trials in experiment 3 only.
filter(is.element(sub,includedSubs)) %>% # only use subs included in RT anlayses for consistency
summarise(meanAcc = mean(correct)) # average wtihin subjects
# summarize accuracy results
condAccMeans=exp.accuracy %>%
group_by(conditionName) %>%
summarize(avgCondAcc=mean(meanAcc), sdCondRT=sd(meanAcc))
categAccMeans=exp.accuracy %>%
group_by(category) %>%
summarize(avgCondAcc=mean(meanAcc), sdCondRT=sd(meanAcc))
# descriptive means (mixed v uniform)
UniMixAcc=round(condAccMeans$avgCondAcc*100,2)
CategoryAccs=round(categAccMeans$avgCondAcc*100,2)
# ANOVA
accuracyResults=ezANOVA(dv= .(meanAcc), wid= .(sub), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.accuracy), type=3)
partialEtaSquared=accuracyResults$ANOVA$SSn/(accuracyResults$ANOVA$SSn + accuracyResults$ANOVA$SSd)
## Calculate descriptive statistics: Means and SD
avgByCondAndCat=exp.tidy %>%
group_by(conditionName,category,sub) %>%
summarise(meanRT= mean(RT))
# Report descriptives
condMeans=avgByCondAndCat %>%
group_by(conditionName) %>%
summarize(avgCondRT=mean(meanRT), sdCondRT=sd(meanRT))
UniMixRT=round(condMeans$avgCondRT,0)
UniMixRT_SDs=round(condMeans$sdCondRT,0)
# now by category
categoryMeans=avgByCondAndCat %>%
group_by(category) %>%
summarize(avgCatRT=mean(meanRT), sdCatRT=sd(meanRT))
# output category means
CategoryRT=round(categoryMeans$avgCatRT,0)
Category_SDs=round(categoryMeans$sdCatRT,0)
## Inferential statistics: ANOVA and mixed-effects model
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.tidy), type=3)
partialEtaSquaredRT=RTResults$ANOVA$SSn/(RTResults$ANOVA$SSn + RTResults$ANOVA$SSd)
## Cohens DZ calculation
avgByCond=exp.tidy %>%
group_by(conditionName,sub) %>%
summarise(meanRT= mean(RT))
effectBySub=avgByCond$meanRT[avgByCond$conditionName=='uniform']-avgByCond$meanRT[avgByCond$conditionName=='mixed']
dz=mean(effectBySub)/sd(effectBySub)
tidyFileName = paste(expName,"_Tidy.txt",sep="")
write.table(exp.tidy, file = tidyFileName, sep="\t")
## Comparing E1 vs. E2
#e1tidy=read_tsv("data_tidy/Animacy_Tidy.txt")
#e2tidy=read_tsv("data_tidy/Size_Tidy.txt")
##Inferential statistics: Mixed-effects models
# Fixed effects of category and condition, and random effects of subjects and target items on the intercept, and random slopes for the effect of condition on subjects
# Note: no effect modeled of condition on targetItems; model fails to converge.
# Maximum model
exp.MaxModel <- lmer(RT ~ category*conditionName + (1 + conditionName|sub) + (1+ conditionName|targetItem), data=exp.tidy, REML=TRUE)
## Do we need random slopes on subjects?
exp.ModelMod1 <- lmer(RT ~ category*conditionName + (1|sub) + (1+ conditionName|targetItem), data=exp.tidy, REML=TRUE)
summary(exp.ModelMod1)
anova(exp.ModelMod1,exp.MaxModel) # if no difference, can remove random slopes on subjects
## Do we need random slopes on items?
exp.ModelMod2 <- lmer(RT ~ category*conditionName + (1|sub) + (1|targetItem), data=exp.tidy, REML=TRUE)
summary (exp.ModelMod2)
anova(exp.ModelMod1,exp.ModelMod2) # if no difference, can remove random slopes on items
# null model - no fixed factor of condition or it's interactino (i.e., uniform/mixed), same random effects structure
exp.NullModel <- lmer(RT ~ category + (1 |sub) + (1 |targetItem), data=exp.tidy, REML=FALSE)
# Essential model comparison
anova(exp.NullModel,exp.ModelMod2)
e1tidy=read_tsv("data_tidy/Animacy_Tidy.txt")
e1tidy
e1tidy$sub
e1
e1.tidy
e1
exp
exp.tidy
exp.tidy$test
exp.tidy$conditionNum
exp.tidy
exp.tidy$sub
exp.tidy$RT
exp.tidy$correct
exp.tidy$condition
exp.tidy$conditionName
exp.tidy$conditionCheck
exp.tidy$conditionNum
exp.tidy$repeatDist
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and e1ort 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(forcats) #manipulating factors in data frames
library(ez) # for anova
library(lme4)
library(markdown)
## Step 2: Load data
e1 = read_tsv("data/Animacy.txt")
e2 = read_tsv("data/ObjectSize.txt")
##
e1$sub = as.factor(e1$sub)
e2$sub = as.factor(e2$sub)
e1$conditionNum = as.numeric(e1$condition)
e2$conditionNum = as.numeric(e2$condition)
e1$categoryNum = as.numeric(e1$categoryNum)
e2$categoryNum = as.numeric(e2$categoryNum)
## Step 3: Preprocess data
# count how many trials per subject
# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
e1.tidy=e1 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
e2.tidy=e2 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
e1.tidy=e1.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
e2.tidy=e2.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
# Store included subs
includedSubsE1=unique(e1.tidy$sub)
includedSubsE2=unique(e2.tidy$sub)
bothExp=join(e1.tidy, e2.tidy)
e1.tidy
e2.tidy
bothExp=merge(e1.tidy, e2.tidy)
bothExp
cbind(e1.tidy, e2.tidy)
test=cbind(e1.tidy, e2.tidy)
rbind(e1.tidy, e2.tidy)
bothExp=rbind(e1.tidy, e2.tidy)
bothExp
bothExp$category
unique(bothExp$category)
e1$experiment = 'Size'
e1$experiment = 'Animacy'
e1
e1$experiment
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and e1ort 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(forcats) #manipulating factors in data frames
library(ez) # for anova
library(lme4)
library(markdown)
## Step 2: Load data
e1 = read_tsv("data/Animacy.txt")
e2 = read_tsv("data/ObjectSize.txt")
##
e1$sub = as.factor(e1$sub)
e2$sub = as.factor(e2$sub)
e1$conditionNum = as.numeric(e1$condition)
e2$conditionNum = as.numeric(e2$condition)
e1$categoryNum = as.numeric(e1$categoryNum)
e2$categoryNum = as.numeric(e2$categoryNum)
e1$experiment = 'Animacy'
e2$experiment = 'Size'
## Step 3: Preprocess data
# count how many trials per subject
# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
e1.tidy=e1 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
e2.tidy=e2 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
e1.tidy=e1.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
e2.tidy=e2.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
# Store included subs
includedSubsE1=unique(e1.tidy$sub)
includedSubsE2=unique(e2.tidy$sub)
bothExp=rbind(e1.tidy, e2.tidy)
## Inferential statistics: ANOVA and mixed-effects model
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within= .(conditionName), between=.(experiment) detailed=TRUE, data=data.frame(bothExp, type=3)
bothExp
bothExp$experiment
unique(bothExp$experiment)
RTResults
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and e1ort 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(forcats) #manipulating factors in data frames
library(ez) # for anova
library(lme4)
library(markdown)
## Step 2: Load data
e1 = read_tsv("data/Animacy.txt")
e2 = read_tsv("data/ObjectSize.txt")
##
e1$sub = as.factor(e1$sub)
e2$sub = as.factor(e2$sub)
e1$conditionNum = as.numeric(e1$condition)
e2$conditionNum = as.numeric(e2$condition)
e1$categoryNum = as.numeric(e1$categoryNum)
e2$categoryNum = as.numeric(e2$categoryNum)
e1$experiment = 'Animacy'
e2$experiment = 'Size'
## Step 3: Preprocess data
# count how many trials per subject
# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
e1.tidy=e1 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
e2.tidy=e2 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
e1.tidy=e1.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
e2.tidy=e2.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
# Store included subs
includedSubsE1=unique(e1.tidy$sub)
includedSubsE2=unique(e2.tidy$sub)
bothExp=rbind(e1.tidy, e2.tidy)
## Inferential statistics: ANOVA and mixed-effects model
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within= .(conditionName), between=.(experiment) detailed=TRUE, data=data.frame(bothExp, type=3)
RTResults
ezANOVA(dv= .(RT), wid= .(sub), within= .(conditionNum), between=.(experiment) detailed=TRUE, data=data.frame(bothExp, type=3)
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within= .(conditionNum), between =.(experiment), detailed=TRUE, data=data.frame(bothExp, type=3)
)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and e1ort 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(forcats) #manipulating factors in data frames
library(ez) # for anova
library(lme4)
library(markdown)
## Step 2: Load data
e1 = read_tsv("data/Animacy.txt")
e2 = read_tsv("data/ObjectSize.txt")
##
e1$sub = as.factor(e1$sub)
e2$sub = as.factor(e2$sub)
e1$conditionNum = as.factor(e1$condition)
e2$conditionNum = as.factor(e2$condition)
e1$categoryNum = as.factor(e1$categoryNum)
e2$categoryNum = as.factor(e2$categoryNum)
e1$experiment = 'Animacy'
e2$experiment = 'Size'
## Step 3: Preprocess data
# count how many trials per subject
# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
e1.tidy=e1 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
e2.tidy=e2 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
e1.tidy=e1.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
e2.tidy=e2.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
# Store included subs
includedSubsE1=unique(e1.tidy$sub)
includedSubsE2=unique(e2.tidy$sub)
bothExp=rbind(e1.tidy, e2.tidy)
## Inferential statistics: ANOVA and mixed-effects model
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within_full= .(conditionName), between =.(experiment), detailed=TRUE, data=data.frame(bothExp, type=3)
# ## Cohens DZ calculation
# avgByCond=e1.tidy %>%
#   group_by(conditionName,sub) %>%
#   summarise(meanRT= mean(RT))
#
# effectBySub=avgByCond$meanRT[avgByCond$conditionName=='uniform']-avgByCond$meanRT[avgByCond$conditionName=='mixed']
#
# dz=mean(effectBySub)/sd(effectBySub)
#tidyFileName = paste(e1Name,"_Tidy.txt",sep="")
#write.table(e1.tidy, file = tidyFileName, sep="\t")
RTResults
ezANOVA(dv= .(RT), wid= .(sub), within_full= .(conditionName), between =.(experiment), detailed=TRUE, data=data.frame(bothExp, type=3)
)
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within_full= .(conditionName), between =.(experiment), detailed=TRUE, data=data.frame(bothExp, type=3))
RTResults
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within= .(conditionName), between =.(experiment), detailed=TRUE, data=data.frame(bothExp, type=3))
RTResults
bothExp
bothExp$experiment
bothExp$experiment=as.factor(bothExp$experiment)
e1$sub
e2$sub
bothExp$sub
e1.tidy
e1.tidy$sub
unique(e1.tidy$sub)
unique(e2.tidy$sub)
e2.tidy
e2.tidy$sub
unique(e2.tidy$sub)
unique(bothExp$sub)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and e1ort 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(forcats) #manipulating factors in data frames
library(ez) # for anova
library(lme4)
library(markdown)
## Step 2: Load data
e1 = read_tsv("data/Animacy.txt")
e2 = read_tsv("data/ObjectSize.txt")
##
e1$sub=e1$sub+100;
e1$sub = as.factor(e1$sub)
e2$sub = as.factor(e2$sub)
e1$conditionNum = as.factor(e1$condition)
e2$conditionNum = as.factor(e2$condition)
e1$categoryNum = as.factor(e1$categoryNum)
e2$categoryNum = as.factor(e2$categoryNum)
e1$experiment = 'Animacy'
e2$experiment = 'Size'
## Step 3: Preprocess data
# count how many trials per subject
# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
e1.tidy=e1 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
e2.tidy=e2 %>%
filter(RT<4000) %>%
filter(correct==1) %>%
filter(phase=='SixItems') %>%
filter(repeatDist==0) # for technical error trials in e1eriment 3 only.
# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
e1.tidy=e1.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
e2.tidy=e2.tidy %>%
group_by(sub) %>%
mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
filter(indivCountC1>1) %>%
filter(indivCountC2>1) %>%
filter(indivCountC3>1) %>%
filter(indivCountC4>1)
# Store included subs
includedSubsE1=unique(e1.tidy$sub)
includedSubsE2=unique(e2.tidy$sub)
bothExp=rbind(e1.tidy, e2.tidy)
bothExp$experiment=as.factor(bothExp$experiment)
bothExp$sub=as.factor(bothExp$sub)
## Inferential statistics: ANOVA and mixed-effects model
RTResults=ezANOVA(dv= .(RT), wid= .(sub), within= .(conditionName), between =.(experiment), detailed=TRUE, data=data.frame(bothExp, type=3))
# ## Cohens DZ calculation
# avgByCond=e1.tidy %>%
#   group_by(conditionName,sub) %>%
#   summarise(meanRT= mean(RT))
#
# effectBySub=avgByCond$meanRT[avgByCond$conditionName=='uniform']-avgByCond$meanRT[avgByCond$conditionName=='mixed']
#
# dz=mean(effectBySub)/sd(effectBySub)
#tidyFileName = paste(e1Name,"_Tidy.txt",sep="")
#write.table(e1.tidy, file = tidyFileName, sep="\t")
RTResults
14+46
unique(bothExp@sub)
unique(bothExp$sub)
count(unique(bothExp$sub))
sum(unique(bothExp$sub))
(unique(bothExp$sub)>0)
AnimacyBySub=Animacy$meanRT[Animacy$conditionName=='uniform']-Animacy$meanRT[Animacy$conditionName=='mixed']
A
Animacy=e1.tidy %>%
group_by(conditionName,sub) %>%
summarise(meanRT= mean(RT))
AnimacyBySub=Animacy$meanRT[Animacy$conditionName=='uniform']-Animacy$meanRT[Animacy$conditionName=='mixed']
Animacy
AnimacyBySub
mean(AnimacyBySub)
sd(AnimacyBySub)
