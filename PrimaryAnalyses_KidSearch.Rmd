---
title: 'KidSearch Analyses:'
output:
  html_document:
    float: yes
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

## GitHub Documents

Code to reproduce the analyses in manuscript, "Animacy and object size are reflected in preschoolers perceptual similarity computations by the preschool years"

## Step 1: Load packages

```{r}
library(knitr) # for kable table formating
library(readxl) # import excel files
library(forcats) #manipulating factors in data frames
library(ez) # for anova
library(lme4)
source("SEfunctions.R") ## helper code for within subs error bars
library(tidyverse) # for data munging


```

## Step 1: Load data and choose experiment
```{r} 
## Step 2: Load data
e1 = read_tsv("data/Animacy.txt")
e2 = read_tsv("data/ObjectSize.txt")
e3 = read_tsv("data/Edibility.txt")

## Choose experiment!
#exp = e1
#expName = 'Animacy'

#exp = e2
#expName = 'Size'
# 
exp = e3
expName = 'Edibility'
```

## Step 1: Preprocess data
```{r} 

##
exp$subject = as.factor(exp$sub)
exp$conditionNum = as.numeric(exp$condition)
exp$conditionName = as.factor(exp$conditionName)
exp$categoryNum = as.numeric(exp$categoryNum)
exp$category = as.factor(exp$category)

## Step 3: Preprocess data
# count how many trials per subject
trialCount=exp %>%
  dplyr::group_by(subject) %>%
  summarise(trials=sum(phase=='SixItems'), correctTrials=sum(correct==1 & phase=='SixItems'), errors=sum(correct==0 & phase=='SixItems'), slow=sum(RT>4000 & phase=='SixItems' & correct==1))  

# what percentage of all trials were incorrect?
round(mean(trialCount$errors/trialCount$trials)*100,2)

# what percentage of correct trials were slow?
round(mean(trialCount$slow/trialCount$correctTrials)*100,2)

# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
exp.tidy=exp %>%
  filter(RT<4000) %>%
  filter(correct==1) %>%
  filter(phase=='SixItems') %>%
  filter(repeatDist==0) # for technical error trials in experiment 3 only.

# make log RT
exp.tidy$logRT=log(exp.tidy$RT);

# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
exp.tidy=exp.tidy %>%
  group_by(subject) %>%
  mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
  mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
  mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
  mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
  filter(indivCountC1>1) %>%
  filter(indivCountC2>1) %>%
  filter(indivCountC3>1) %>%
  filter(indivCountC4>1) 

# Store included subs
includedSubs=unique(exp.tidy$subject)

# How many trials are included in each condition in this subset of children?
trialCountIncludedSubs=exp.tidy %>%
  group_by(subject) %>% 
  filter(is.element(subject,includedSubs)) %>% 
  summarise(trialCount=length(RT), uniformCount=sum(conditionNum==1), mixedCount=sum(conditionNum==2)) 

# overall how many trials (and sd)
round(mean(trialCountIncludedSubs$trialCount),2)
round(sd(trialCountIncludedSubs$trialCount),2)

# how many trials on average per condition?
round(mean(trialCountIncludedSubs$uniformCount),2)
round(mean(trialCountIncludedSubs$mixedCount),2)

# Compute accuracy means
exp.accuracy=exp %>%
  group_by(subject,conditionName, category) %>%
  filter(phase=='SixItems') %>%
  filter(repeatDist==0) %>% # for technical error trials in experiment 3 only.
  filter(is.element(subject,includedSubs)) %>% # only use subs included in RT anlayses for consistency
  summarise(meanAcc = mean(correct)) # average wtihin subjects


```

## Step 3: Accuracy results
```{r} 

# summarize accuracy results
condAccMeans=exp.accuracy %>%
  group_by(conditionName) %>%
  summarize(avgCondAcc=mean(meanAcc), sdCondRT=sd(meanAcc))

categAccMeans=exp.accuracy %>%
  group_by(category) %>%
  summarize(avgCondAcc=mean(meanAcc), sdCondRT=sd(meanAcc))

# descriptive means (mixed v uniform)
UniMixAcc=round(condAccMeans$avgCondAcc*100,2) 
CategoryAccs=round(categAccMeans$avgCondAcc*100,2) 

# ANOVA
accuracyResults=ezANOVA(dv= .(meanAcc), wid= .(subject), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.accuracy), type=3)
partialEtaSquared=accuracyResults$ANOVA$SSn/(accuracyResults$ANOVA$SSn + accuracyResults$ANOVA$SSd)
```

Children were `r round(UniMixAcc[1],2)`% accurate on `r condAccMeans$conditionName[1]` trials, and  `r round(UniMixAcc[2],2)`% on `r condAccMeans$conditionName[2]` category trials.

Children were `r round(CategoryAccs[1],2)`% accurate on `r categAccMeans$category[1]` trials, and  `r round(CategoryAccs[2],2)`% on `r categAccMeans$category[2]`  trials.

Effect of condition on accuracy: (*F*(1,`r accuracyResults$ANOVA$DFd[2]`)= `r round(accuracyResults$ANOVA$F[2],2)`, *p* = `r round(accuracyResults$ANOVA$p[2],2)`, *partial eta squared*= `r round(partialEtaSquared[2],2)`

Effect of category on accuracy:  (*F*(1,`r accuracyResults$ANOVA$DFd[3]`)= `r round(accuracyResults$ANOVA$F[3],2)`, *p* = `r round(accuracyResults$ANOVA$p[3],2)`, *partial eta squared*= `r round(partialEtaSquared[3],2)`

Effect of their interaction on accuracy:  (*F*(1,`r accuracyResults$ANOVA$DFd[4]`)= `r round(accuracyResults$ANOVA$F[4],2)`, *p* = `r round(accuracyResults$ANOVA$p[4],2)`, *partial eta squared*= `r round(partialEtaSquared[4],2)`


## Step 4: RT results
```{r} 

## Calculate descriptive statistics: Means and SD
avgByCondAndCat=exp.tidy %>%
  group_by(conditionName,category,subject) %>%
  summarise(meanRT= mean(RT))  

avgByCondAndCatLog=exp.tidy %>%
  dplyr::group_by(conditionName,category,subject) %>%
  summarise(medLog = median(logRT))  


# Report descriptives
condMeans=avgByCondAndCat %>%
  group_by(conditionName) %>%
  summarize(avgCondRT=mean(meanRT), sdCondRT=sd(meanRT))

UniMixRT=round(condMeans$avgCondRT,0) 
UniMixRT_SDs=round(condMeans$sdCondRT,0) 

# now by category
categoryMeans=avgByCondAndCat %>%
  group_by(category) %>%
  summarize(avgCatRT=mean(meanRT), sdCatRT=sd(meanRT))

# output category means
CategoryRT=round(categoryMeans$avgCatRT,0) 
Category_SDs=round(categoryMeans$sdCatRT,0) 

## Inferential statistics: ANOVA and mixed-effects model
RTResults=ezANOVA(dv= .(RT), wid= .(subject), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.tidy), type=3)
partialEtaSquaredRT=RTResults$ANOVA$SSn/(RTResults$ANOVA$SSn + RTResults$ANOVA$SSd)

## with log RT? Check to be sure this is the same.
RTResults_Log=ezANOVA(dv= .(logRT), wid= .(subject), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.tidy), type=3)
partialEtaSquaredRT=RTResults$ANOVA$SSn/(RTResults$ANOVA$SSn + RTResults$ANOVA$SSd)


# Save cleaned data for e1 and e2 to compare them in next sript.
#tidyFileName = paste(expName,"_Tidy.txt",sep="")
#write.table(exp.tidy, file = tidyFileName, sep="\t")

## Cohens DZ calculation
avgByCond=exp.tidy %>%
  group_by(conditionName,subject) %>%
  summarise(meanRT= mean(RT))

effectBySub=avgByCond$meanRT[avgByCond$conditionName=='uniform']-avgByCond$meanRT[avgByCond$conditionName=='mixed']
dz=mean(effectBySub)/sd(effectBySub)

# get summary for plotting
plotSummary=summarySEwithin(data=exp.tidy, measurevar="RT", withinvars=c("conditionName","category"), idvar="subject")

# Make quick plot
library(ggthemes)
library(ggplot2)
plotLimits=c(1000,2500)
dodge <- position_dodge(width = 0.9)
ggplot(plotSummary, aes(x=category,y=RT, fill=conditionName)) +
  geom_bar(stat="identity", position=dodge) +  # plot the point
  geom_errorbar(aes(ymin=RT-se, ymax=RT+se), width=.1, position=dodge) + # make some error bars
  coord_cartesian(ylim=plotLimits) + # ugh, need this for some reason with bar plots
  theme_hc(base_size=14)  + ## change ggplot theme, number here modulates size of text
  theme(axis.ticks.x=element_blank(),    axis.ticks.y=element_blank()) +
  theme(text=element_text(family="Helvetica Light")) + 
  labs(x="", y="Search speed (ms)") + # kill redudant x label +
  ggtitle("Mean RT by Condition & Category")

```

Children took `r round(UniMixRT[1],0)`ms on `r condMeans$conditionName[1]` category trials, and  `r round(UniMixRT[2],0)`ms on `r condMeans$conditionName[2]` category trials.

Children took `r round(CategoryRT[1],0)`ms on `r categoryMeans$category[1]` trials, and  `r round(CategoryRT[2],0)`ms on `r categoryMeans$category[2]` trials.

Effect of condition on RT: (*F*(1,`r RTResults$ANOVA$DFd[2]`)= `r round(RTResults$ANOVA$F[2],2)`, *p* = `r round(RTResults$ANOVA$p[2],2)`, *partial eta squared*= `r round(partialEtaSquaredRT[2],2)`

Effect of category on RT:  (*F*(1,`r RTResults$ANOVA$DFd[2]`) = `r round(RTResults$ANOVA$F[3],2)`, *p* = `r round(RTResults$ANOVA$p[3],2)`, *partial eta squared*= `r round(partialEtaSquaredRT[3],2)`

Effect of their interaction on RT:  (*F*(1,`r RTResults$ANOVA$DFd[2]`) = `r round(RTResults$ANOVA$F[4],2)`, *p* = `r round(RTResults$ANOVA$p[4],2)`, *partial eta squared*= `r round(partialEtaSquaredRT[4],2)`

Cohens DZ for condition of interest (uniform vs. mixed): Cohens *dz* = `r round(dz,2)`


```{r} 

##Inferential statistics: Mixed-effects models
# Fixed effects of category and condition, and random effects of subjects and target items on the intercept, and random slopes for the effect of condition on subjects
# Note: no effect modeled of condition on targetItems; model fails to converge.

# Maximum model 
exp.MaxModel <- lmer(RT ~ category*conditionName + (1 + conditionName|sub) + (1+ conditionName|targetItem), data=exp.tidy, REML=TRUE)

## Do we need random slopes on subjects?
exp.ModelMod1 <- lmer(RT ~ category*conditionName + (1|sub) + (1+ conditionName|targetItem), data=exp.tidy, REML=TRUE) 
summary(exp.ModelMod1)
anova(exp.ModelMod1,exp.MaxModel) # if no difference, can remove random slopes on subjects

## Do we need random slopes on items?
exp.ModelMod2 <- lmer(RT ~ category*conditionName + (1|sub) + (1|targetItem), data=exp.tidy, REML=TRUE) 
summary (exp.ModelMod2)
anova(exp.ModelMod1,exp.ModelMod2) # if no difference, can remove random slopes on items

# null model - no fixed factor of condition or it's interactino (i.e., uniform/mixed), same random effects structure
exp.NullModel <- lmer(RT ~ category + (1 |sub) + (1 |targetItem), data=exp.tidy, REML=FALSE)

# Essential model comparison
anova(exp.NullModel,exp.ModelMod2)


```
Summary:

E1: Animacy: Maximum model fails to converge, as does a model with either random slopes on subjects or random slopes on target items.  Probably because less data overall than E2 or E3.

E2: Object Size: Maximum models and models with random slopes do converge. Random slopes have somewhat high correlation with the intercept, but don't explain extra variance.

E3:Edibility: Random effect of condition on subjects (i.e., "(1 + conditionName|sub)") had a perfect negative correlation with the intercept, suggesting that it was not explaining variance. Similarily, the random effects of condition on items also had a very high negative correlation with the intercept.




