---
title: 'KidSearch Analyses:'
output:
  html_document:
    float: yes
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```
## GitHub Documents

Code to reproduce the analyses in manuscript, "Animacy and object size are reflected in preschoolers perceptual similarity computations by the preschool years"

## Step 1: Load data and choose experiment
```{r} 
#
library(readxl) # import excel files
library(tidyverse) # for data munging

e1 = read_tsv("data/Animacy.txt")
e2 = read_tsv("data/ObjectSize.txt")

## Choose experiment!
exp = e1
expName = 'Animacy'

#exp = e2
#expName = 'Size'

```

## Step 2: Load most packages

```{r}
library(knitr) # for kable table formating
library(forcats) #manipulating factors in data frames
library(ez) # for anova
library(lme4)
library(ggthemes)
library(ggplot2)
library(langcog) #multi_boot_standard function for bootstrapping CIs
library(lmerTest)
```

## Step 3: Preprocess data
```{r} 

##
exp$subject = as.factor(exp$sub)
exp$conditionNum = as.numeric(exp$condition)
exp$conditionName = as.factor(exp$conditionName)
exp$categoryNum = as.numeric(exp$categoryNum)
exp$category = as.factor(exp$category)

## Step 3: Preprocess data
# count how many trials per subject
trialCount=exp %>%
  dplyr::group_by(subject) %>%
  summarise(trials=sum(phase=='SixItems'), correctTrials=sum(correct==1 & phase=='SixItems'), errors=sum(correct==0 & phase=='SixItems'), slow=sum(RT>4000 & phase=='SixItems' & correct==1))  

# what percentage of all trials were incorrect?
round(mean(trialCount$errors/trialCount$trials)*100,2)

# what percentage of correct trials were slow?
round(mean(trialCount$slow/trialCount$correctTrials)*100,2)

# Only get data with correct trials less than 4 seconds long when there were six items on the screen.
exp.tidy=exp %>%
  filter(RT<4000) %>%
  filter(correct==1) %>%
  filter(phase=='SixItems') 

# also construct dataset without RT trimming
exp.tidy.notrim=exp %>%
  filter(RT<10000) %>%
  filter(correct==1) %>%
  filter(phase=='SixItems') 

# make log RT
exp.tidy$logRT=log(exp.tidy$RT);

# Now only include subjects who had more than 1 trial speeded trial in each of 4 conditions
exp.tidy=exp.tidy %>%
  dplyr::group_by(subject) %>%
  mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
  mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
  mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
  mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
  filter(indivCountC1>1) %>%
  filter(indivCountC2>1) %>%
  filter(indivCountC3>1) %>%
  filter(indivCountC4>1) 

# for both versions of dataset
exp.tidy.notrim=exp.tidy.notrim %>%
  dplyr::group_by(subject) %>%
  mutate(indivCountC1=sum(conditionNum==1 & categoryNum==1)) %>%
  mutate(indivCountC2=sum(conditionNum==1 & categoryNum==2)) %>%
  mutate(indivCountC3=sum(conditionNum==2 & categoryNum==1)) %>%
  mutate(indivCountC4=sum(conditionNum==2 & categoryNum==2)) %>%
  filter(indivCountC1>1) %>%
  filter(indivCountC2>1) %>%
  filter(indivCountC3>1) %>%
  filter(indivCountC4>1) 

# Store included subs
includedSubs=unique(exp.tidy$subject)

# How many trials are included in each condition in this subset of children?
trialCountIncludedSubs=exp.tidy %>%
  dplyr::group_by(subject) %>% 
  filter(is.element(subject,includedSubs)) %>% 
  dplyr::summarise(trialCount=length(RT), uniformCount=sum(conditionNum==1), mixedCount=sum(conditionNum==2)) 

# overall how many trials (and sd)
round(mean(trialCountIncludedSubs$trialCount),2)
round(sd(trialCountIncludedSubs$trialCount),2)

# how many trials on average per condition?
round(mean(trialCountIncludedSubs$uniformCount),2)
round(mean(trialCountIncludedSubs$mixedCount),2)

# Compute accuracy means
exp.accuracy <- exp %>%
  dplyr::group_by(subject,conditionName, category) %>%
  filter(phase=='SixItems') %>%
  filter(is.element(subject,includedSubs)) %>% # only use subs included in RT anlayses for consistency
  dplyr::summarise(meanAcc = mean(correct)) # average wtihin subjects



```



## Step 4: Accuracy results
```{r} 
# summarize accuracy results
condAccMeans=exp.accuracy %>%
  dplyr::group_by(conditionName) %>%
  dplyr::summarize(avgCondAcc=mean(meanAcc), sdCondRT=sd(meanAcc))

categAccMeans=exp.accuracy %>%
  dplyr::group_by(category) %>%
  dplyr::summarize(avgCondAcc=mean(meanAcc), sdCondRT=sd(meanAcc))

# descriptive means (mixed v uniform)
UniMixAcc=round(condAccMeans$avgCondAcc*100,2) 
CategoryAccs=round(categAccMeans$avgCondAcc*100,2) 

# ANOVA
accuracyResults=ezANOVA(dv= .(meanAcc), wid= .(subject), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.accuracy), type=3)
partialEtaSquared=accuracyResults$ANOVA$SSn/(accuracyResults$ANOVA$SSn + accuracyResults$ANOVA$SSd)
```

Children were `r round(UniMixAcc[1],2)`% accurate on `r condAccMeans$conditionName[1]` trials, and  `r round(UniMixAcc[2],2)`% on `r condAccMeans$conditionName[2]` category trials.

Children were `r round(CategoryAccs[1],2)`% accurate on `r categAccMeans$category[1]` trials, and  `r round(CategoryAccs[2],2)`% on `r categAccMeans$category[2]`  trials.

Effect of condition on accuracy: (*F*(1,`r accuracyResults$ANOVA$DFd[2]`)= `r round(accuracyResults$ANOVA$F[2],2)`, *p* = `r round(accuracyResults$ANOVA$p[2],2)`, *partial eta squared*= `r round(partialEtaSquared[2],2)`

Effect of category on accuracy:  (*F*(1,`r accuracyResults$ANOVA$DFd[3]`)= `r round(accuracyResults$ANOVA$F[3],2)`, *p* = `r round(accuracyResults$ANOVA$p[3],2)`, *partial eta squared*= `r round(partialEtaSquared[3],2)`

Effect of their interaction on accuracy:  (*F*(1,`r accuracyResults$ANOVA$DFd[4]`)= `r round(accuracyResults$ANOVA$F[4],2)`, *p* = `r round(accuracyResults$ANOVA$p[4],2)`, *partial eta squared*= `r round(partialEtaSquared[4],2)`


## Step 5: RT results
```{r} 

## Calculate descriptive statistics: Means and SD
avgByCondAndCat=exp.tidy %>%
  dplyr::group_by(conditionName,category,subject) %>%
  dplyr::summarise(meanRT= mean(RT))  

avgByCondAndCatLog=exp.tidy %>%
  dplyr::group_by(conditionName,category,subject) %>%
  dplyr::summarise(medLog = median(logRT))  

# Report descriptives
condMeans=avgByCondAndCat %>%
  dplyr::group_by(conditionName) %>%
  dplyr::summarize(avgCondRT=mean(meanRT), sdCondRT=sd(meanRT))

UniMixRT=round(condMeans$avgCondRT,0) 
UniMixRT_SDs=round(condMeans$sdCondRT,0) 

# now by category
categoryMeans=avgByCondAndCat %>%
  dplyr::group_by(category) %>%
  dplyr::summarize(avgCatRT=mean(meanRT), sdCatRT=sd(meanRT))

# output category means
CategoryRT=round(categoryMeans$avgCatRT,0) 
Category_SDs=round(categoryMeans$sdCatRT,0) 

## Inferential statistics: ANOVA 
RTResults=ezANOVA(dv= .(RT), wid= .(subject), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.tidy), type=3)
partialEtaSquaredRT=RTResults$ANOVA$SSn/(RTResults$ANOVA$SSn + RTResults$ANOVA$SSd)

RTResults_NoTrim=ezANOVA(dv= .(RT), wid= .(subject), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.tidy.notrim), type=3)
partialEtaSquaredRT=RTResults$ANOVA$SSn/(RTResults$ANOVA$SSn + RTResults$ANOVA$SSd)

# ezDesign(exp.tidy, x = RT, y = subject, row = conditionName, col = category)

## with log RT? Check to be sure this is the same.
RTResults_Log=ezANOVA(dv= .(logRT), wid= .(subject), within= .(conditionName, category), detailed=TRUE, data=data.frame(exp.tidy), type=3)
partialEtaSquaredRT=RTResults$ANOVA$SSn/(RTResults$ANOVA$SSn + RTResults$ANOVA$SSd)

## Cohens DZ calculation
avgByCond=exp.tidy %>%
  dplyr::group_by(conditionName,subject) %>%
  dplyr::summarise(meanRT= mean(RT))

effectBySub=avgByCond$meanRT[avgByCond$conditionName=='uniform']-avgByCond$meanRT[avgByCond$conditionName=='mixed']
dz=mean(effectBySub)/sd(effectBySub)

```

### Output table of RT results
```{r}
kable(RTResults)
```


### Output table of RT results without trimming
```{r}
kable(RTResults_NoTrim)
```


### How reliable are these effects? Compute in 100 random halves of the data (not reported in MS, supplemental)
```{r}
if (expName=="Animacy"){
  fewerSubs=8 # half
}
  
if (expName=="Size") {
  fewerSubs=16  # size of exp 1
}

dz_splitHalf = array()
condEffect_splitHalf = array()
sig_out = array()
for (iter in 1:1000){
  theseSubs = sample(unique(exp.tidy$sub),fewerSubs)
  avgByCond_Split <- avgByCond %>%
    filter(is.element(subject,theseSubs)) 
  temp=avgByCond_Split$meanRT[avgByCond_Split$conditionName=='uniform']-avgByCond_Split$meanRT[avgByCond_Split$conditionName=='mixed']
  dz_splitHalf[iter]=mean(temp)/sd(temp)
  condEffect_splitHalf[iter]=mean(temp)
  out = t.test(temp)
  p_val = out[3]$p.value
  sig_out[iter]=p_val
}

# how often would we have found an effect in these samples?
# sum(sig_out<.05)/5
```
Average cohen's d in 100 random halves of the data = `r mean(dz_splitHalf)`, with SD = `r sd(dz_splitHalf)`
Average congruency effect in 100 random halves of the data = `r mean(condEffect_splitHalf)`


### Make plot (Figure 2)
```{r}
plotSummary<- exp.tidy %>%
  group_by(subject,category,conditionName) %>%
  dplyr::summarize(meanRT = mean(RT)) %>%
  group_by(category,conditionName) %>%
  multi_boot_standard(col = "meanRT")
  

if (expName=="Animacy"){
  levels(plotSummary$category) = c("Animal Targets","Inanimate Targets")
  levels(plotSummary$conditionName) = c("Uniform Animacy","Mixed Animacy")
  relevel(plotSummary$conditionName,ref="Uniform Animacy")}

if (expName=="Size"){
  levels(plotSummary$category) = c("Big Object \n Targets","Small Object \n Targets")
  levels(plotSummary$conditionName) = c("Uniform Size","Mixed Size")
  relevel(plotSummary$conditionName,ref="Uniform Size")}
  

# Make plot
plotLimits=c(1000,2500)
dodge <- position_dodge(width = 0.9)
(plot_out = ggplot(plotSummary, aes(x=category,y=mean, fill=conditionName)) +
  geom_bar(stat="identity", position=dodge, width=.8) +  # plot the point
  geom_pointrange(aes(ymin=ci_lower, ymax=ci_upper), width=.1, position=dodge, alpha=.5) +
  coord_cartesian(ylim=plotLimits) + # ugh, need this for some reason with bar plots
  theme_hc(base_size=16)  + ## change ggplot theme, number here modulates size of text
  theme(axis.ticks.x=element_blank(),   axis.ticks.y=element_blank()) +
  scale_fill_manual(values = c("#58595B","#D3D3D3"), guide="legend")+
  theme(text=element_text(family="Helvetica")) + 
  theme(aspect.ratio=1) + 
  labs(x="", y="Search speed (ms)") + # kill redudant x label +
  # ggtitle("Mean RT by Condition & Category") +
  theme(legend.title = element_blank(),
           legend.justification=c(0,1), 
           legend.position=c(0, 1.2),  
           legend.background = element_blank(),
           legend.key = element_blank()))

ggsave(paste0('Figure2_', expName, '.pdf'), width = 4, height = 5,unit =  "in", plot = plot_out, path="figures", device = "pdf",dpi = 300)
```

Children took `r round(UniMixRT[1],0)`ms on `r condMeans$conditionName[1]` category trials, and  `r round(UniMixRT[2],0)`ms on `r condMeans$conditionName[2]` category trials.

Children took `r round(CategoryRT[1],0)`ms on `r categoryMeans$category[1]` trials, and  `r round(CategoryRT[2],0)`ms on `r categoryMeans$category[2]` trials.

Effect of condition on RT: (*F*(1,`r RTResults$ANOVA$DFd[2]`)= `r round(RTResults$ANOVA$F[2],2)`, *p* = `r round(RTResults$ANOVA$p[2],2)`, *partial eta squared*= `r round(partialEtaSquaredRT[2],2)`

Effect of category on RT:  (*F*(1,`r RTResults$ANOVA$DFd[2]`) = `r round(RTResults$ANOVA$F[3],2)`, *p* = `r round(RTResults$ANOVA$p[3],2)`, *partial eta squared*= `r round(partialEtaSquaredRT[3],2)`

Effect of their interaction on RT:  (*F*(1,`r RTResults$ANOVA$DFd[2]`) = `r round(RTResults$ANOVA$F[4],2)`, *p* = `r round(RTResults$ANOVA$p[4],2)`, *partial eta squared*= `r round(partialEtaSquaredRT[4],2)`

Cohens DZ for condition of interest (uniform vs. mixed): Cohens *dz* = `r round(dz,2)`

We found the same pattern of effects when we included trials slower than 4 seconds (still excluding trials with RTs>10 seconds, *F*(1,`r RTResults_NoTrim$ANOVA$DFd[2]`)= `r round(RTResults_NoTrim$ANOVA$F[2],2)`, *p* = `r round(RTResults_NoTrim$ANOVA$p[2],2)`

## Step 6: Mixed effect models
```{r} 

##Inferential statistics: Mixed-effects models
# Note: no effect modeled of condition on targetItems; model fails to converge.

# Fixed effects of category and condition, and random effects of subjects and target items on the intercept, 
mainModel.report <- lmer(log(RT) ~ category*conditionName + (1|sub) + (1|targetItem), data=exp.tidy, REML=TRUE)
mainModel.compare <- lmer(log(RT) ~ category*conditionName + (1|sub) + (1|targetItem), data=exp.tidy, REML=FALSE)

# null model - no fixed factor of condition or it's interaction (i.e., uniform/mixed), same random effects structure as exp.MainModel
nullModel<- lmer(log(RT) ~ category + (1|sub) + (1|targetItem), data=exp.tidy, REML=FALSE)

# Essential model comparison
anova(mainModel.compare, nullModel)

model_out = summary(mainModel.report)
kable(summary(mainModel.report)$coef)

```

This result was confired using linear mixed-effect models (B = `r round(model_out$coef[3,1],2)`, SE = `r round(model_out$coef[3,2],2)`, t =  `r round(model_out$coef[3,4],2)`, p =  `r round(model_out$coef[3,5],3)`)



## Reviewer questions: 
### (1) Is there a relationship between number of trials completed by each child and overall accuracy?
```{r}
trialCount <- trialCount %>%
  mutate(avg_correct = correctTrials / trials) 

# plot it
ggplot(trialCount, aes(x=trials, y=avg_correct)) +
  geom_point() +
  xlab('Number of test trials completed') +
  ylab('Average percent correct on test trials') +
  theme_few()

# Were children who compeleted more trials likely to be more acccurate?
trials_by_overall_acc = cor.test(trialCount$trials, trialCount$avg_correct)
kable(trialCount)
```


### (2) Do children who complete more trials show a greater mixed-effect accuracy benefit?
```{r}

trials_by_acc_effect<- exp %>%
  dplyr::group_by(subject,conditionName) %>%
  filter(phase=='SixItems') %>%
  filter(is.element(subject,includedSubs)) %>% # only use subs included in RT anlayses for consistency
  summarize(trial_count = n(), condition_acc = mean(correct)) %>%
  summarize(trial_count_total = trial_count[conditionName=="mixed"] + trial_count[conditionName=="uniform"], cong_effect = condition_acc[conditionName=="mixed"] - condition_acc[conditionName=="uniform"])

ggplot(trials_by_acc_effect, aes(x=trial_count_total, y=cong_effect)) +
  geom_point() +
  xlab('Number of test trials completed') +
  ylab('Congruency RT effect') +
  theme_few()



# Were children who compeleted more trials likely to show a congruency accuracy effect?
trials_by_acc_cong = cor.test(trials_by_acc_effect$trial_count_total, trials_by_acc_effect$cong_effect)

```


### (3) Do children who complete more trials show a greater mixed-effect RT benefit?
```{r}
trials_by_RT_effect <- exp.tidy %>%
  group_by(sub, conditionName) %>%
  summarize(trial_count = n(), condition_rt = mean(RT)) %>%
  summarize(trial_count_total = trial_count[conditionName=="mixed"] + trial_count[conditionName=="uniform"], cong_effect = condition_rt[conditionName=="uniform"] - condition_rt[conditionName=="mixed"])

ggplot(trials_by_RT_effect, aes(x=trial_count_total, y=cong_effect)) +
  geom_point() +
  xlab('Number of test trials completed') +
  ylab('Congruency RT effect') +
  theme_few()

# Were children who compeleted more trials likely to show a congruency RT effect?
trials_by_RT_cong = cor.test(trials_by_RT_effect$trial_count_total, trials_by_RT_effect$cong_effect)
```


Overall, we found that children who completed more trials were not necessarily likely to be more accurate (r = `r trials_by_overall_acc$estimate`, p = `r trials_by_overall_acc$p.value`) or show a mixed-effect benefit in their RTs (r = `r trials_by_RT_cong$estimate`, p = `r trials_by_RT_cong$p.value`); however, we found mild evidence that they might be more likely to show a mixed-effect benefits in their accuracy scores  (r = `r trials_by_acc_cong$estimate`, p = `r trials_by_acc_cong$p.value`). 
